{
  "1": {
    "inputs": {
      "ckpt_name": "wai-illustrious-sdxl.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "2": {
    "inputs": {
      "text": "lowres, bad anatomy, bad hands, worst quality, low quality, blurry, \nrealistic, 3d, photorealistic, watermark, text, signature, \n(deformed iris:1.4), (deformed pupils:1.4), cropped, out of frame,\njpeg artifacts, duplicate, morbid, mutilated, extra fingers, overexposed, blown out highlights, pixelated lighting, \nharsh lighting, compression artifacts, jpeg artifacts, \nbanding, posterization",
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "3": {
    "inputs": {
      "text": "masterpiece, best quality, absurdres, 1girl, Makotono Aoi, sensitive, year 2025, indoors, teacher's room, solo, tomboy, very short hair, blue hair, parted bangs, very handsome face, yellow eyes, large breasts, a adult tomboy girl with very boyish handsome shortcut blue hair with (parted bangs:1.2) and pixie cut and very handsome face and yellow eyes and perfect female body and large breasts wearing teacher suit and tight miniskirt and shirt and pantystocking and high heels and sitting on chair with crossed legs and closed mouth, soft cinematic lighting, anime, (sharp focus:1.1), (vibrant colors:1.1)",
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "4": {
    "inputs": {
      "seed": 208414574609287,
      "steps": 30,
      "cfg": 6,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "1",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "2",
        0
      ],
      "latent_image": [
        "9",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "9": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "12": {
    "inputs": {
      "upscale_method": "bilinear",
      "width": 2048,
      "height": 2048,
      "crop": "disabled",
      "samples": [
        "4",
        0
      ]
    },
    "class_type": "LatentUpscale",
    "_meta": {
      "title": "Upscale Latent"
    }
  },
  "13": {
    "inputs": {
      "seed": 745659293098033,
      "steps": 15,
      "cfg": 6,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 0.52,
      "model": [
        "1",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "2",
        0
      ],
      "latent_image": [
        "12",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "14": {
    "inputs": {
      "samples": [
        "13",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "15": {
    "inputs": {
      "guide_size": 384,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": 524173439679483,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.4,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5,
      "bbox_dilation": 10,
      "bbox_crop_factor": 3,
      "sam_detection_hint": "center-1",
      "sam_dilation": 0,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 10,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "tiled_encode": false,
      "tiled_decode": false,
      "image": [
        "14",
        0
      ],
      "model": [
        "1",
        0
      ],
      "clip": [
        "1",
        1
      ],
      "vae": [
        "1",
        2
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "2",
        0
      ],
      "bbox_detector": [
        "17",
        0
      ],
      "sam_model_opt": [
        "26",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "FaceDetailer"
    }
  },
  "17": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "21": {
    "inputs": {
      "guide_size": 768,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": 783994903787850,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.4,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5,
      "bbox_dilation": 10,
      "bbox_crop_factor": 1.5,
      "sam_detection_hint": "center-1",
      "sam_dilation": 0,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "tiled_encode": false,
      "tiled_decode": false,
      "image": [
        "15",
        0
      ],
      "model": [
        "1",
        0
      ],
      "clip": [
        "1",
        1
      ],
      "vae": [
        "1",
        2
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "2",
        0
      ],
      "bbox_detector": [
        "17",
        0
      ],
      "sam_model_opt": [
        "25",
        0
      ],
      "segm_detector_opt": [
        "23",
        1
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "FaceDetailer"
    }
  },
  "22": {
    "inputs": {
      "filename_prefix": "anime_hires",
      "images": [
        "21",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "23": {
    "inputs": {
      "model_name": "segm/person_yolov8m-seg.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "25": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAMLoader (Impact)"
    }
  },
  "26": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAMLoader (Impact)"
    }
  }
}